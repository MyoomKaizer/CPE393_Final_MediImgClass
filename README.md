# iSeg 2017 Brain Segmentation - MLOps Pipeline

A complete MLOps pipeline for brain MRI segmentation using the iSeg 2017 dataset. This project demonstrates medical imaging, deep learning, workflow orchestration, and production-ready ML practices.

## ğŸ¯ Project Overview

This pipeline performs automatic 4-class brain tissue segmentation from multimodal MRI (T1 and T2 weighted images):
- **Classes**: Cerebrospinal Fluid (CSF), Gray Matter (GM), White Matter (WM), Background
- **Architecture**: U-Net with encoder-decoder structure
- **Input**: T1 and T2 weighted MRI volumes (iSeg 2017 dataset)
- **Output**: 3D segmentation predictions in NIfTI format

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  Airflow Orchestration                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  - Data Validation                                      â”‚
â”‚  - Model Training (U-Net, TensorFlow/Keras)             â”‚
â”‚  - Inference on Multiple Subjects                       â”‚
â”‚  - Visualization & Reporting                            â”‚
â”‚  - MLflow Experiment Tracking                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Docker Containerization                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â€¢ iseg_trainer: Training & Inference Container         â”‚
â”‚  â€¢ airflow_webserver: Orchestration UI                  â”‚
â”‚  â€¢ mlflow_server: Experiment Tracking & Model Registry  â”‚
â”‚  â€¢ postgres: Airflow & MLflow Metadata                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“‹ Prerequisites

- **Docker** (with Docker Compose)
- **Windows PowerShell 5.1+** (or Bash/Linux equivalent)
- **~10GB disk space** (for data + models)
- **GPU optional** (CPU-based inference is supported)

## ğŸš€ Quick Start

### 1. Clone and Setup
```powershell
cd C:\Users\<username>\Repo\ML\CPE393_Final_MediImgClass
```

### 2. Start the Stack
```powershell
docker-compose up -d
```

This starts:
- **Airflow WebServer**: http://localhost:8080
- **MLflow UI**: http://localhost:5000
- **PostgreSQL**: Internal database

### 3. Verify Services
```powershell
docker-compose ps
```

All containers should show `Up` status and healthy health checks.

### 4. Run the Pipeline

**Via Airflow UI:**
1. Navigate to http://localhost:8080
2. Login with default credentials (admin/admin)
3. Find `iseg_brain_segmentation_pipeline` DAG
4. Click the **play button** to trigger manually

**Via CLI:**
```powershell
docker exec airflow_scheduler airflow dags trigger iseg_brain_segmentation_pipeline
docker logs -f airflow_scheduler
```

## ğŸ“ Project Structure

```
.
â”œâ”€â”€ src/                             # Main Python package (all production code)
â”‚   â”œâ”€â”€ __init__.py                  # Package exports (build_unet, load_subjects, etc.)
â”‚   â”œâ”€â”€ models.py                    # U-Net architecture definition
â”‚   â”œâ”€â”€ preprocess.py                # Data loading & preprocessing utilities
â”‚   â”œâ”€â”€ train.py                     # Training pipeline with MLflow integration
â”‚   â”œâ”€â”€ inference.py                 # Inference with predictions & logging
â”‚   â”œâ”€â”€ view_hdr.py                  # HDR volume visualization
â”‚   â””â”€â”€ view_predict_slice.py        # Prediction slice visualization & logging
â”œâ”€â”€ dags/
â”‚   â””â”€â”€ pipeline_dag.py              # Airflow DAG orchestration
â”œâ”€â”€ data/
â”‚   â””â”€â”€ iSeg-2017-Training/          # MRI dataset (not in repo)
â”œâ”€â”€ models/
â”‚   â””â”€â”€ unet_stage1_4class.keras     # Trained model output
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ subject-*-pred.nii.gz        # Inference predictions
â”‚   â””â”€â”€ pipeline_report_*.json       # Pipeline execution reports
â”œâ”€â”€ logs/
â”‚   â””â”€â”€ [Airflow & Docker logs]
â”œâ”€â”€ Dockerfile                       # Training container
â”œâ”€â”€ Dockerfile.airflow               # Airflow extensions
â”œâ”€â”€ docker-compose.yml               # Multi-service orchestration
â”œâ”€â”€ requirements.txt                 # Python dependencies
â””â”€â”€ README.md                        # Documentation
```

### Key Files

The project contains only essential files:
- **src/** - All production-ready code in Python package format
- **dags/** - Airflow orchestration definitions
- **data/**, **models/**, **outputs/** - Data directories (mounted in Docker)
- **Dockerfile**, **docker-compose.yml** - Container configuration
- **requirements.txt** - Python dependencies

## ğŸ“¦ Package Architecture

All code is organized in the `src/` Python package for clean separation between production code and configuration files.

### Execution Flow

**Docker Training:**
```
Docker container runs: python -m src.train
  â†“
src/train.py main() function executes
  â”œâ”€ imports from src.models
  â”œâ”€ imports from src.preprocess
  â””â”€ logs to MLflow at http://mlflow:5000
```

**Docker Inference:**
```
Airflow DAG runs: python -m src.inference --subject-id N
  â†“
src/inference.py parse_args() and run_inference() execute
  â”œâ”€ imports from src.preprocess
  â”œâ”€ loads model from /app/models/
  â””â”€ logs to MLflow
```

**Airflow Orchestration:**
```
Airflow DAG (dags/pipeline_dag.py) executes:
  â”œâ”€ Data validation (Python in Airflow container)
  â”œâ”€ Training: DockerOperator â†’ python -m src.train
  â”œâ”€ Inference: DockerOperator â†’ python -m src.inference --subject-id {1,2,3}
  â””â”€ Visualization & reporting (Python in Airflow container)
```

### Module Dependencies

```
src/__init__.py
  â””â”€ exports: build_unet, build_unet_stage1, load_subjects, create_slice_dataset, normalize_volume

src/models.py (dependencies: tensorflow, keras)
  â””â”€ Defines: conv_block(), build_unet(), build_unet_stage1()

src/preprocess.py (dependencies: nibabel, scikit-learn, scikit-image, numpy)
  â””â”€ Defines: load_subjects(), create_slice_dataset(), normalize_volume()

src/train.py (dependencies: src.models, src.preprocess, mlflow, tensorflow)
  â””â”€ Defines: main() - full training pipeline with MLflow tracking

src/inference.py (dependencies: src.preprocess, nibabel, mlflow, tensorflow)
  â””â”€ Defines: parse_args(), run_inference(), _load_volume()

src/view_hdr.py (dependencies: nibabel, matplotlib)
  â””â”€ Defines: view_hdr_volume() - 3D volume visualization

src/view_predict_slice.py (dependencies: nibabel, mlflow, matplotlib)
  â””â”€ Defines: view_and_log_slices(), parse_args() - slice visualization & MLflow logging
```

## ğŸ”§ Configuration

### Environment Variables (docker-compose.yml)

```yaml
MLFLOW_TRACKING_URI: "http://mlflow:5000"
AIRFLOW_UID: 50000
PYTHONUNBUFFERED: "1"
```

### Pipeline Parameters (dags/pipeline_dag.py)

```python
EPOCHS = 10
BATCH_SIZE = 4
MODEL_NAME = "iSeg4ClassUNet"
DATA_DIR = "/app/data/iSeg-2017-Training"
```

### Dataset

The iSeg 2017 dataset must be placed in `./data/iSeg-2017-Training/` with structure:
```
iSeg-2017-Training/
â”œâ”€â”€ subject-1-T1.hdr
â”œâ”€â”€ subject-1-T1.img
â”œâ”€â”€ subject-1-T2.hdr
â”œâ”€â”€ subject-1-T2.img
â”œâ”€â”€ subject-1-label.hdr
â”œâ”€â”€ subject-1-label.img
â”œâ”€â”€ subject-2-T1.hdr
â””â”€â”€ [... more subjects ...]
```

## ğŸ“Š Pipeline Tasks

### 1. Data Validation (`validate_data`)
- Checks for required data files (T1, T2, labels)
- Counts available subjects
- Validates directory structure

### 2. Model Check (`check_model`)
- Checks if trained model exists
- Determines if retraining is needed

### 3. Training Decision (`decide_train`)
- **Branch Task**: Routes to training or skipping
- If model exists: Skip training
- If not: Proceed to training

### 4. Model Training (`train_model`)
- Runs in Docker container with TensorFlow/Keras
- Trains U-Net for 10 epochs
- Logs metrics to MLflow
- Saves best model checkpoint
- Logs model artifacts

### 5. Inference Tasks (`inference_tasks`)
- **Parallel execution** on subjects 1-3
- Runs in Docker containers
- Generates predictions in NIfTI format
- Logs inference metrics to MLflow

### 6. Visualization (`visualize_predictions`)
- Creates 2D slices from 3D predictions
- Generates comparison images
- Logs visualizations as artifacts

### 7. Reporting (`generate_report`)
- Creates JSON summary report
- Logs pipeline execution details
- Records training/inference metrics

## ğŸ“ˆ MLflow Integration

All experiments and model artifacts are tracked in MLflow:

**Access MLflow UI:** http://localhost:5000

**Features:**
- âœ“ Experiment tracking for training runs
- âœ“ Metrics logging (loss, accuracy, inference time)
- âœ“ Artifacts storage (models, predictions, visualizations)
- âœ“ Model versioning and comparison

**Example metrics tracked:**
```
Training:
- loss, accuracy per epoch
- val_loss, val_accuracy
- training_time_sec
- model artifacts

Inference:
- inference_time_sec per subject
- prediction outputs
- visualization images
```

## ğŸ³ Docker Containers

### iseg_trainer:latest
- **Base**: python:3.9-slim
- **Purpose**: Training & Inference execution
- **Packages**: TensorFlow 2.20, Keras, MLflow 2.16.0, nibabel, scikit-image
- **Volumes**: `/app/data`, `/app/models`, `/app/outputs`

### airflow_webserver & airflow_scheduler
- **Base**: apache/airflow:2.7.3-python3.9
- **Purpose**: Workflow orchestration and UI
- **Features**: Docker provider, MLflow integration

### mlflow_server
- **Image**: ghcr.io/mlflow/mlflow:v2.16.0
- **Purpose**: Experiment tracking and model registry
- **Storage**: SQLite database + artifact store

### postgres
- **Image**: postgres:14
- **Purpose**: Metadata storage for Airflow & MLflow

## ğŸ”„ Workflow

```
START
  â†“
[validate_data] â†’ Checks if data exists
  â†“
[check_model] â†’ Checks if model exists
  â†“
[decide_train] â†’ Branch decision
  â”œâ”€ YES â†’ [train_model] â†’ Trains U-Net (MLflow logged)
  â””â”€ NO  â†’ [skip_train] â†’ Dummy task
  â†“
[train_done] â†’ Join point
  â†“
[inference_tasks] â†’ Parallel inference on subjects 1-3
  â”œâ”€ [inference_subject_1]
  â”œâ”€ [inference_subject_2]
  â””â”€ [inference_subject_3]
  â†“
[visualize_predictions] â†’ Generate visualizations
  â†“
[generate_report] â†’ Create summary report
  â†“
END (Success/Failure)
```

## ğŸ“Š Expected Output

After successful pipeline execution:

```
outputs/
â”œâ”€â”€ subject-1-pred.nii.gz          # 3D prediction volume
â”œâ”€â”€ subject-2-pred.nii.gz          # 3D prediction volume
â”œâ”€â”€ subject-3-pred.nii.gz          # 3D prediction volume
â”œâ”€â”€ pipeline_report_20251125.json  # Execution summary
â””â”€â”€ [visualization artifacts in MLflow]

models/
â””â”€â”€ unet_stage1_4class.keras       # Trained model

MLflow UI (http://localhost:5000):
â”œâ”€â”€ Experiment: iSeg-4Class-Segmentation
â”‚   â”œâ”€â”€ Training Run
â”‚   â”‚   â”œâ”€â”€ Parameters: epochs=10, batch_size=4
â”‚   â”‚   â”œâ”€â”€ Metrics: final_val_loss, final_val_accuracy
â”‚   â”‚   â””â”€â”€ Artifacts: trained model
â”‚   â””â”€â”€ Multiple Inference Runs
â”‚       â”œâ”€â”€ Metrics: inference_time_sec
â”‚       â””â”€â”€ Artifacts: predictions, visualizations
```

## ğŸ› ï¸ Development & Debugging

### View Logs

**Airflow Scheduler:**
```powershell
docker logs -f airflow_scheduler
```

**Airflow Webserver:**
```powershell
docker logs -f airflow_webserver
```

**MLflow Server:**
```powershell
docker logs -f mlflow_server
```

**Training Container (during execution):**
```powershell
docker logs <container_id>
```

### Rebuild Containers

If dependencies change:
```powershell
docker build --no-cache -t iseg_trainer:latest .
docker-compose up -d --build
```

### Reset Everything

```powershell
docker-compose down
docker volume rm cpe393_final_mediimgclass_postgres_data cpe393_final_mediimgclass_mlflow_data
docker-compose up -d
```

### Manual Testing

Test training locally:
```powershell
docker run --rm `
  --network iseg_network `
  -v ${PWD}/data:/app/data `
  -v ${PWD}/models:/app/models `
  -e MLFLOW_TRACKING_URI=http://mlflow:5000 `
  iseg_trainer:latest python train.py
```

Test inference:
```powershell
docker run --rm `
  --network iseg_network `
  -v ${PWD}/data:/app/data `
  -v ${PWD}/models:/app/models `
  -v ${PWD}/outputs:/app/outputs `
  -e MLFLOW_TRACKING_URI=http://mlflow:5000 `
  iseg_trainer:latest python inference.py --subject-id 1
```

## âš ï¸ Known Issues & Troubleshooting

### MLflow Server Not Healthy
**Symptom**: MLflow container keeps restarting

**Solution**:
```powershell
docker-compose down
Remove-Item -Recurse -Force .\mlflow_data
docker-compose up -d
```

### Training Takes Too Long
**Solution**: Reduce EPOCHS in pipeline_dag.py (default: 10)

### Inference Fails - "ModuleNotFoundError: nibabel"
**Cause**: Airflow container doesn't have ML dependencies

**Solution**: Ensure inference runs in DockerOperator (âœ“ Fixed in current version)

### Out of Memory
**Solution**: Reduce BATCH_SIZE in train.py (default: 4 â†’ try 2)

## ğŸ“š References

- **iSeg 2017 Dataset**: http://iseg2017.web.unc.edu/
- **Airflow Documentation**: https://airflow.apache.org/
- **MLflow Documentation**: https://mlflow.org/
- **TensorFlow/Keras**: https://www.tensorflow.org/
- **Docker Compose**: https://docs.docker.com/compose/

## ğŸ“ License

Project for CPE393 - Machine Learning in Production

## ğŸ‘¥ Author

Poonnawat Nontanakcheevin 65070503424
Pongpong Prakobnoppakao 65070503426
Pataraphol Pholngam 65070503432
Garice Denoncin 68540460043
Enzhuo Cao 68540470003
Created for CPE393 Final Project - Medical Image Segmentation MLOps Pipeline

---

**Last Updated**: November 25, 2025
**Status**: âœ… Fully Functional - All Components Tested
